{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-oRijAoUwpp2Qlz-Kl3k6hNlodWQyf87","timestamp":1694474450134}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"37puETfgRzzg"},"source":["# Data Preprocessing Tools"]},{"cell_type":"markdown","metadata":{"id":"EoRP98MpR-qj"},"source":["## Importing the libraries"]},{"cell_type":"code","source":["#import libraries by matplotlib, pandas, and numpy\n","#sklearn has all Machine learning libraries and packages"],"metadata":{"id":"JbjR_aT41AJE","executionInfo":{"status":"ok","timestamp":1719870166795,"user_tz":300,"elapsed":177,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["import numpy as np #np is a shortcut for numpy\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"Xz6uvRdhkkxX","executionInfo":{"status":"ok","timestamp":1719870167965,"user_tz":300,"elapsed":189,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RopL7tUZSQkT"},"source":["## Importing the dataset"]},{"cell_type":"code","source":["#create a new variable for my data set\n","#read_csv function is inside of pandas library so we have to call pandas first\n","#and then call read_csv"],"metadata":{"id":"Q0gAGeCp1DmW","executionInfo":{"status":"ok","timestamp":1719870169616,"user_tz":300,"elapsed":148,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["dataset = pd.read_csv('Data.csv')\n","#to get x (matrix of features), get all the first ith columns except the last one\n","#iloc is a function to locate indices\n","#featured columns (independent) are those that we use them to guess some properties\n","X = dataset.iloc[:, :-1].values  #-1 is the last column\n","#we only want to get the index of last column\n","#dependent variable are usually stored in the last column\n","y = dataset.iloc[:, -1].values"],"metadata":{"id":"C5-QwgOynbqM","executionInfo":{"status":"ok","timestamp":1719870171152,"user_tz":300,"elapsed":172,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"id":"qZguX1iMvifD","executionInfo":{"status":"ok","timestamp":1719870172638,"user_tz":300,"elapsed":188,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"067c8eb9-6e9e-49db-d8d1-28b252bdf98d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(y)"],"metadata":{"id":"SxbObpX6vklh","executionInfo":{"status":"ok","timestamp":1719870174222,"user_tz":300,"elapsed":171,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"b930f7b9-09c5-4ba6-c8bd-3be3019f4a25","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"]}]},{"cell_type":"markdown","metadata":{"id":"nhfKXNxlSabC"},"source":["## Taking care of missing data"]},{"cell_type":"code","source":["#one naive apporach would be deleting missing data\n","#but when we have too much missing data that is not a good approach\n","#the second approach will be replacing the missing data with average salary"],"metadata":{"id":"aFx-OZ7IavHP","executionInfo":{"status":"ok","timestamp":1719870175906,"user_tz":300,"elapsed":172,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["#imputer is an object from SimpleImputer class and sklearn is a library\n","#fit, transform are also a method\n","#we need to find all numerical columns to replace any missing values"],"metadata":{"id":"jCG1mmnv1S_W","executionInfo":{"status":"ok","timestamp":1719870176880,"user_tz":300,"elapsed":186,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#from library import class SimpleImputer\n","from sklearn.impute import SimpleImputer\n","#instance of this class is imputer\n","#replace missing value with mean\n","imputer = SimpleImputer(missing_values= np.nan, strategy = 'mean')\n","#select all numerical columns (not categorical cols) here columns 1 and 2\n","#columns indices start from 0\n","imputer.fit(X[:, 1:3])\n","X[:, 1:3] = imputer.transform(X[:, 1:3])"],"metadata":{"id":"2KHR82Sja8aO","executionInfo":{"status":"ok","timestamp":1719870178283,"user_tz":300,"elapsed":166,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UQ-06W0Ics7F","executionInfo":{"status":"ok","timestamp":1719870180876,"user_tz":300,"elapsed":176,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"876328bb-dde3-457a-b079-bf881eb9690c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CriG6VzVSjcK"},"source":["## Encoding categorical data"]},{"cell_type":"code","source":["#Suppose in a large data set we have only 3 categorical data like (Spain, Germany, Italy)\n","#so we group them in 3 columns and assign a binary id to them like: 001, 010, ..."],"metadata":{"id":"9ZRaWmhc1ZCO","executionInfo":{"status":"ok","timestamp":1719870182955,"user_tz":300,"elapsed":166,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# we can change categorical data to some numerical data like Germany = 0, France = 1, Spain = 2\n","# we also can convert these categorical data to a binary vector\n","# change No to 0 and Yes to 1"],"metadata":{"id":"fvGdMTEKfLr8","executionInfo":{"status":"ok","timestamp":1719870183837,"user_tz":300,"elapsed":160,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AhSpdQWeSsFh"},"source":["### Encoding the Independent Variable"]},{"cell_type":"code","source":["#object from ColumnTransformer class\n","#encode the first column (categorical col which is also independent)\n","#instead of having one column since we vectorized the categorical column\n","#we have three columns\n","#first column for France, second for Germany, and third for Spain"],"metadata":{"id":"essiFJhih3IU","executionInfo":{"status":"ok","timestamp":1719870185696,"user_tz":300,"elapsed":168,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","#ct is an object of ColumnTransformer class\n","ct = ColumnTransformer(transformers =[('encoder', OneHotEncoder(), [0])], remainder = 'passthrough')\n","#the first column [0] is our categorical column that we want to encode it\n","X = np.array(ct.fit_transform(X)) # pass ct.fit_transform(X) to numpy array to force it as an array"],"metadata":{"id":"sAZDh6yPfzQv","executionInfo":{"status":"ok","timestamp":1719870187705,"user_tz":300,"elapsed":165,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lu42HZsxhKIX","executionInfo":{"status":"ok","timestamp":1719870189515,"user_tz":300,"elapsed":163,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"9842beea-0463-46f1-eb7e-50b72f802527"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"DXh8oVSITIc6"},"source":["### Encoding the Dependent Variable"]},{"cell_type":"code","source":["#this time we encode the dependent variable (last column)\n","#the last column is Yes/No and it is very easy and it is just a label"],"metadata":{"id":"7RHaHtP8iKPP","executionInfo":{"status":"ok","timestamp":1719870299486,"user_tz":300,"elapsed":160,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","le= LabelEncoder()\n","y = le.fit_transform(y) # we don't need to convert it to an array"],"metadata":{"id":"MOXRpH9EiCs7","executionInfo":{"status":"ok","timestamp":1719870307565,"user_tz":300,"elapsed":201,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJxa2665ioM5","executionInfo":{"status":"ok","timestamp":1719870309147,"user_tz":300,"elapsed":169,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"10f0a0a0-50db-40de-f67e-5ea17d6b55f2"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"markdown","source":["# Splitting the dataset into the Training set and Test set"],"metadata":{"id":"PS6LRlVtq9RX"}},{"cell_type":"code","source":["#which one is correct? feature scaling after splitting dataset or\n","#before splitting? Correct answer: AFTER splitting the dataset\n","#it prevents information leakage for test set"],"metadata":{"id":"V-DXcgZ11k0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we have to apply feature scaling \"after\" splitting the dataset\n","# into the training set and test set, ow. we face the information leakage\n","# feature scaling shouldn't be applied on test set"],"metadata":{"id":"tkRV9XjKrPMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","#80% for train set and 20% for test set\n","# random_state is a seed\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1 )"],"metadata":{"id":"Lhwv_3EJrcbY","executionInfo":{"status":"ok","timestamp":1719872295707,"user_tz":300,"elapsed":184,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["print(X_train)\n","#we have only 8 rows since overall we have 10 cases and 20% is for test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOOxwx25tDhg","executionInfo":{"status":"ok","timestamp":1719872297093,"user_tz":300,"elapsed":177,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"7d7a7623-06ce-467d-c066-b7be4513b899"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COY0QuSdtDoG","executionInfo":{"status":"ok","timestamp":1719872420226,"user_tz":300,"elapsed":188,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"87100506-b277-4df1-b259-5dce7d68206f"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(y_train) # corresponds to the first 8 rows (customers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UEQ76y3FtDt0","executionInfo":{"status":"ok","timestamp":1719872421541,"user_tz":300,"elapsed":175,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"30c26c83-44d5-4460-93da-ec371fec6d74"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1]\n"]}]},{"cell_type":"code","source":["print(y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssVpLfG_tD0U","executionInfo":{"status":"ok","timestamp":1719872423241,"user_tz":300,"elapsed":185,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"e4b12783-3e9e-4175-d5ca-bfabb33956df"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1]\n"]}]},{"cell_type":"markdown","source":["# Feature Scaling"],"metadata":{"id":"Oir0sdsqrvH_"}},{"cell_type":"code","source":["# we use standardisation and normalization"],"metadata":{"id":"-JMx18Wrryrv","executionInfo":{"status":"ok","timestamp":1719873229590,"user_tz":300,"elapsed":213,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","# do we have to apply standardisation (feature scaling) to dummy node (the encoded categorical nodes)? no\n","# so we only apply standardisation on columns 4 and 5 (3 and 4), we don't have the last column in X_train\n","X_train [:, 3:] = sc.fit_transform(X_train [:, 3:]) # to get the mean and standard deviation\n","#X_train values are between [-2,+2] here (overall [-3,+3])\n","X_test [:, 3:] = sc.transform(X_test [:, 3:])\n","# we just get the result for test so don't apply fit_transform\n"],"metadata":{"id":"QJKwPriYxNZS","executionInfo":{"status":"ok","timestamp":1719873575186,"user_tz":300,"elapsed":164,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o55kcKgJzGZl","executionInfo":{"status":"ok","timestamp":1719873577073,"user_tz":300,"elapsed":181,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"8e642a12-1f8f-496e-e062-f0d416ac096d"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 -0.1915918438457856 -1.0781259408412427]\n"," [0.0 1.0 0.0 -0.014117293757057902 -0.07013167641635401]\n"," [1.0 0.0 0.0 0.5667085065333239 0.6335624327104546]\n"," [0.0 0.0 1.0 -0.3045301939022488 -0.30786617274297895]\n"," [0.0 0.0 1.0 -1.901801144700799 -1.4204636155515822]\n"," [1.0 0.0 0.0 1.1475343068237056 1.2326533634535488]\n"," [0.0 1.0 0.0 1.4379472069688966 1.5749910381638883]\n"," [1.0 0.0 0.0 -0.7401495441200352 -0.5646194287757336]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POoK59AyzGgI","executionInfo":{"status":"ok","timestamp":1719873638193,"user_tz":300,"elapsed":176,"user":{"displayName":"Sanaz Rabinia","userId":"18423678739563779329"}},"outputId":"d656b938-8e9f-427e-e267-a0fe394ca712"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 -1.4661817944830127 -0.9069571034860731]\n"," [1.0 0.0 0.0 -0.44973664397484425 0.20564033932253029]]\n"]}]}]}